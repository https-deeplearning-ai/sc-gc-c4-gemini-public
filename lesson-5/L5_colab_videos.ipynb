{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ZjNqTQeHDq1P",
   "metadata": {
    "id": "ZjNqTQeHDq1P"
   },
   "outputs": [],
   "source": [
    "# Copyright 2024 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d16354bd-ca40-4f17-a6b6-384a63a99dc7",
   "metadata": {},
   "source": [
    "<table class=\"tfo-notebook-buttons\" align=\"left\">\n",
    "  <td>\n",
    "    <a target=\"_blank\" href=\"https://colab.sandbox.google.com/github/https-deeplearning-ai/sc-gc-c4-gemini-public/blob/main/lesson-5/L5_colab_videos.ipynb\"><img src=\"https://www.tensorflow.org/images/colab_logo_32px.png\" />Run in Google Colab</a>\n",
    "  </td>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfac2391-3a90-4c2a-b860-55356a8b8930",
   "metadata": {},
   "source": [
    "# Cost Estimate\n",
    "\n",
    "The estimated cost of running this notebook once using your Google Cloud account, using `Gemini 1.5 Flash`, without \"Finding a Needle in a Haystack\" example (which has been converted to markdown) should be less than 0.20 USD (as of August 2024). Get the latest Gemini costs [here](https://cloud.google.com/vertex-ai/generative-ai/pricing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "WVSuCx8fAlCJ",
   "metadata": {
    "id": "WVSuCx8fAlCJ"
   },
   "source": [
    "# SETUP\n",
    "\n",
    "This is follow up to the [How to Set Up your Google Cloud Account](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/9/how-to-set-up-your-google-cloud-account-|-try-it-out-yourself-[optional]) instructions from the course, [Large Multimodal Model Prompting with Gemini](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/1/introduction) on the [Learning Platform](https://learn.deeplearning.ai) of [DeepLearning.AI](https://www.deeplearning.ai)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "kxyOUgGuD1cB",
   "metadata": {
    "id": "kxyOUgGuD1cB"
   },
   "source": [
    "### Install Vertex AI SDK and other Required Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "fV6kVGI6D3Qx",
   "metadata": {
    "id": "fV6kVGI6D3Qx"
   },
   "outputs": [],
   "source": [
    "%pip install --upgrade --user --quiet google-cloud-aiplatform"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ohM3m2TBD4-A",
   "metadata": {
    "id": "ohM3m2TBD4-A"
   },
   "source": [
    "### Restart Runtime\n",
    "\n",
    "To use the newly installed packages in this Jupyter runtime, you must restart the runtime. You can do this by running the cell below, which restarts the current kernel.\n",
    "\n",
    "The restart might take a minute or longer. After it's restarted, continue to the next step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "_VFkGMCxD7IS",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_VFkGMCxD7IS",
    "outputId": "d92cfd4d-eb06-4d02-f1b1-657513e7fa05"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'status': 'ok', 'restart': True}"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import IPython\n",
    "\n",
    "app = IPython.Application.instance()\n",
    "app.kernel.do_shutdown(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7wBEATTEEII5",
   "metadata": {
    "id": "7wBEATTEEII5"
   },
   "source": [
    "### Authenticate your Notebook Environment (Colab Only)\n",
    "\n",
    "If you're running this notebook on Google Colab, run the cell below to authenticate your environment.\n",
    "\n",
    "**NOTE:** The Gmail email address you use to authenticate this lesson colab must be the same as the one you used to set up your Google Cloud account and your Project."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "NHvtRAsQEJUE",
   "metadata": {
    "id": "NHvtRAsQEJUE"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "if \"google.colab\" in sys.modules:\n",
    "    from google.colab import auth\n",
    "\n",
    "    auth.authenticate_user()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "wcjLp7syENBX",
   "metadata": {
    "id": "wcjLp7syENBX"
   },
   "source": [
    "### Set Google Cloud Project Information and Initialize Vertex AI SDK\n",
    "\n",
    "**Add _your_ Project ID below**, which you created while following the [How to Set Up your Google Cloud Account](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/9/how-to-set-up-your-google-cloud-account-|-try-it-out-yourself-[optional]) instructions. If your `Project ID` was `dlai-shortcourse-on-gemini`, then you can run the cell below as it is. Otherwise, be sure to change it.\n",
    "\n",
    "You can also look up your Project ID in your [Project Dashboard](https://console.cloud.google.com/projectselector2/home/dashboard)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1WDlDM8uENqR",
   "metadata": {
    "id": "1WDlDM8uENqR"
   },
   "outputs": [],
   "source": [
    "PROJECT_ID = \"dlai-shortcourse-on-gemini\"  # @param {type:\"string\"}\n",
    "LOCATION = \"us-central1\"  # @param {type:\"string\"}\n",
    "\n",
    "\n",
    "import vertexai\n",
    "\n",
    "vertexai.init(project=PROJECT_ID, location=LOCATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "CJspoqjXBOgZ",
   "metadata": {
    "id": "CJspoqjXBOgZ"
   },
   "source": [
    "# IN COURSE VIDEO\n",
    "\n",
    "Lesson video starts from below."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679851f7-54ed-437d-ae67-1d173913bb28",
   "metadata": {
    "id": "679851f7-54ed-437d-ae67-1d173913bb28"
   },
   "source": [
    "# [Lesson 5: Developing Use Cases with Videos](https://learn.deeplearning.ai/courses/large-multimodal-model-prompting-with-gemini/lesson/6/developing-use-cases-videos)\n",
    "\n",
    "In this lesson, you'll go through Gemini's Multimodality capabilities, by passing Videos and Texts as input."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a14c80d-e9e2-4ba2-9362-388736225365",
   "metadata": {
    "id": "7a14c80d-e9e2-4ba2-9362-388736225365"
   },
   "source": [
    "**Note:** In the latest version, `from vertexai.preview.generative_models` has been changed to `from vertexai.generative_models`.\n",
    "\n",
    "`from vertexai.preview.generative_models` can still be used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "27015df2-de75-4a34-9756-ef5ffc58a647",
   "metadata": {
    "id": "27015df2-de75-4a34-9756-ef5ffc58a647",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.generative_models import GenerativeModel"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "507beaa1-662b-4a78-90f0-6218c4c91d00",
   "metadata": {
    "id": "507beaa1-662b-4a78-90f0-6218c4c91d00"
   },
   "source": [
    "- Load the `gemini-pro-vision` model.\n",
    "- When specifying `gemini-pro-vision`, the [gemini-1.0-pro-vision](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-pro-vision) model is used.\n",
    "\n",
    "**Note:** In the video, `gemini-pro-vision` was used, which you can do so as well. Or use `gemini-1.5-flash-001`, which is dramatically less cheaper than `gemini-pro-vision`. You can take a look at pricing [here](https://cloud.google.com/vertex-ai/generative-ai/pricing)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "036be85c-2783-4930-ba11-1943e1229c80",
   "metadata": {},
   "source": [
    "```Python\n",
    "multimodal_model = GenerativeModel(\"gemini-pro-vision\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d49b1dae-ecdd-4c31-bd23-770890273382",
   "metadata": {
    "id": "d49b1dae-ecdd-4c31-bd23-770890273382",
    "tags": []
   },
   "outputs": [],
   "source": [
    "multimodal_model = GenerativeModel(\"gemini-1.5-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99cb7797-709f-450f-bc35-6a8df4eab2fe",
   "metadata": {
    "id": "99cb7797-709f-450f-bc35-6a8df4eab2fe"
   },
   "source": [
    "## Digital Marketer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f0970ab-f175-47c1-95f0-aa815b0cbe7f",
   "metadata": {
    "id": "4f0970ab-f175-47c1-95f0-aa815b0cbe7f",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path_1 = \"dlai-sc-gemini-bucket/vertex-ai-langchain.mp4\"\n",
    "video_uri_1 = f\"gs://{file_path_1}\"\n",
    "video_url_1 = f\"https://storage.googleapis.com/{file_path_1}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d49ab4a5-66ee-492e-abc8-01c3de7b8bf0",
   "metadata": {
    "id": "d49ab4a5-66ee-492e-abc8-01c3de7b8bf0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import IPython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bbcb3eda-4c1b-4d9d-abcb-445de4001d0e",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "bbcb3eda-4c1b-4d9d-abcb-445de4001d0e",
    "outputId": "5a50d88f-1b09-4f15-fee5-acc3a27bd384",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/dlai-sc-gemini-bucket/vertex-ai-langchain.mp4\" controls  width=\"450\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IPython.display.Video(video_url_1, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c3884d16-1ad1-4b51-9df4-af2d01ee5d48",
   "metadata": {
    "id": "c3884d16-1ad1-4b51-9df4-af2d01ee5d48",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from vertexai.generative_models import (\n",
    "    GenerationConfig,\n",
    "    GenerativeModel,\n",
    "    Part,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "78f3ed51-3275-4ecd-979c-7e8b7a4576ad",
   "metadata": {
    "id": "78f3ed51-3275-4ecd-979c-7e8b7a4576ad",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_1 = Part.from_uri(video_uri_1, mime_type=\"video/mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a7fe8a7-9a36-4507-ba6d-eeb65eaf4de3",
   "metadata": {
    "id": "3a7fe8a7-9a36-4507-ba6d-eeb65eaf4de3"
   },
   "source": [
    "- Structure your prompt(s).\n",
    "- Be specific with what you want the model to do for you.\n",
    "- You can even specify the output format of the response from the model.\n",
    "- In this case, you are asking for the response to be in JSON format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "945f492e-1abf-402f-b449-361620ee10b9",
   "metadata": {
    "id": "945f492e-1abf-402f-b449-361620ee10b9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = \"\"\"\n",
    "You are a great digital marketer working on a new video.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6a759702-d13c-47cf-a858-61c60f89b95a",
   "metadata": {
    "id": "6a759702-d13c-47cf-a858-61c60f89b95a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "tasks = \"\"\"\n",
    "You will add the video to your website and to do this you\n",
    "need to complete some tasks. Please make sure your answer\n",
    "is structured.\n",
    "\n",
    "Tasks:\n",
    "- What is the title of the video?\n",
    "- Write a summary of what is in the video.\n",
    "- Generate metadata for the video in JSON that includes:\\\n",
    "Title, short description, language, and company.\n",
    "\"\"\"\n",
    "\n",
    "# tasks = \"\"\"\n",
    "# You will add the video to your website and to do this you\n",
    "# need to complete some tasks. Please make sure your answer\n",
    "# is structured.\n",
    "\n",
    "# Tasks:\n",
    "# - What is the title of the video?\n",
    "# - Write a summary of what is in the video.\n",
    "# - Generate metadata for the video that includes:\\\n",
    "# Title, short description, language, and company.\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb8bdbed-890c-435d-90ba-6328722dac39",
   "metadata": {
    "id": "fb8bdbed-890c-435d-90ba-6328722dac39"
   },
   "source": [
    "- You can choose the number of variables you want for your prompt.\n",
    "- More variables means you have more flexibility in making specific changes to your prompts while keeping everyhting else the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9791c1d6-39af-44f6-b633-212df6315138",
   "metadata": {
    "id": "9791c1d6-39af-44f6-b633-212df6315138",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# format_json = \"Please output the metadata in JSON\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1185aa10-ece7-473d-aaa5-243185e84d42",
   "metadata": {
    "id": "1185aa10-ece7-473d-aaa5-243185e84d42",
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents_1 = [video_1, role, tasks]\n",
    "\n",
    "# contents_1 = [video_1, role, tasks, format_json]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "171592df-1777-4b32-99ac-ff0ac42eadda",
   "metadata": {
    "id": "171592df-1777-4b32-99ac-ff0ac42eadda"
   },
   "source": [
    "- Feel free to change the `temperature`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8527c49-8a9f-4f8f-988f-5ccc8dc216d3",
   "metadata": {
    "id": "d8527c49-8a9f-4f8f-988f-5ccc8dc216d3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config_1 = GenerationConfig(\n",
    "    temperature=0.1,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "40e4e8d7-8028-46d4-9eac-6e2dc803db17",
   "metadata": {
    "id": "40e4e8d7-8028-46d4-9eac-6e2dc803db17",
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = multimodal_model.generate_content(\n",
    "    contents_1,\n",
    "    generation_config=generation_config_1,\n",
    "    stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16350384-1495-4ebc-9ddf-0b0746525a0c",
   "metadata": {
    "id": "16350384-1495-4ebc-9ddf-0b0746525a0c"
   },
   "source": [
    "**Note**: If you set `stream=True`, you'll print your responses as:\n",
    "```Python\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6c4d91-1251-4b83-a4e8-89075e33c49c",
   "metadata": {
    "id": "3a6c4d91-1251-4b83-a4e8-89075e33c49c"
   },
   "source": [
    "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "956a46c4-e4e4-4979-9c1b-bebec2f05fb1",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "956a46c4-e4e4-4979-9c1b-bebec2f05fb1",
    "outputId": "eb1f393c-af7e-4da2-8b70-aff144b75c2d",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the tasks you requested:\n",
      "\n",
      "- **Title of the video:** Build AI-powered apps on Vertex AI with LangChain\n",
      "- **Summary of the video:** This video explains how to use Vertex AI and LangChain to build AI-powered applications. The video covers common design patterns for using large language models, including how to include data from external sources and how to chain multiple models together. The video also shows how to use Vertex AI extensions to deploy LangChain applications.\n",
      "- **Metadata for the video in JSON:**\n",
      "```json\n",
      "{\n",
      "  \"Title\": \"Build AI-powered apps on Vertex AI with LangChain\",\n",
      "  \"short description\": \"Learn how to use Vertex AI and LangChain to build AI-powered applications. This video covers common design patterns, including how to include data from external sources and how to chain multiple models together. It also shows how to use Vertex AI extensions to deploy LangChain applications.\",\n",
      "  \"language\": \"English\",\n",
      "  \"company\": \"Google Cloud\"\n",
      "}\n",
      "``` \n"
     ]
    }
   ],
   "source": [
    "print(responses.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a9b1931-8e9a-4ac2-84cc-445df7c9743f",
   "metadata": {
    "id": "4a9b1931-8e9a-4ac2-84cc-445df7c9743f"
   },
   "source": [
    "# Explaining the Educational Concepts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "054120fd-cf97-4e5b-92b8-11fd7e2b3771",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "054120fd-cf97-4e5b-92b8-11fd7e2b3771",
    "outputId": "5d135a56-a57e-4f73-a5eb-a8f976634946",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/dlai-sc-gemini-bucket/descending-into-ml.mp4\" controls  width=\"450\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_2 = \"dlai-sc-gemini-bucket/descending-into-ml.mp4\"\n",
    "video_uri_2 = f\"gs://{file_path_2}\"\n",
    "video_url_2 = f\"https://storage.googleapis.com/{file_path_2}\"\n",
    "\n",
    "IPython.display.Video(video_url_2, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "3e9be4b6-f508-4cd0-b885-cdb60bc6280b",
   "metadata": {
    "id": "3e9be4b6-f508-4cd0-b885-cdb60bc6280b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_2 = Part.from_uri(video_uri_2, mime_type=\"video/mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a5bb786-74bf-40c7-ab55-f8b6f031ee1c",
   "metadata": {
    "id": "7a5bb786-74bf-40c7-ab55-f8b6f031ee1c"
   },
   "source": [
    "- You can even ask the model to answer based on answers of previous questions.\n",
    "- And to generate programming code based on previous answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "3fa902fe-91f6-48f7-ae0d-4792f35398a5",
   "metadata": {
    "id": "3fa902fe-91f6-48f7-ae0d-4792f35398a5",
    "tags": []
   },
   "outputs": [],
   "source": [
    "prompt = \"\"\"\n",
    "Please have a look at the video and answer the following\n",
    "questions.\n",
    "\n",
    "Questions:\n",
    "- Question 1: Which concept is explained in the video?\n",
    "- Question 2: Based on your answer to Question 1,\n",
    "can you explain the basic math of this concept?\n",
    "- Question 3: Can you provide a simple scikit code example\n",
    "explaining the concept?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d24e5781-4f61-4d44-a7b6-4ce497fc54da",
   "metadata": {
    "id": "d24e5781-4f61-4d44-a7b6-4ce497fc54da",
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents_2 = [video_2, prompt]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "29a15d96-8d6f-4a71-b5c2-3b00fe54eeb2",
   "metadata": {
    "id": "29a15d96-8d6f-4a71-b5c2-3b00fe54eeb2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = multimodal_model.generate_content(\n",
    "    contents_2,\n",
    "    stream=False\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d093c488-d7bd-4210-8ac5-550daa6ce614",
   "metadata": {
    "id": "d093c488-d7bd-4210-8ac5-550daa6ce614"
   },
   "source": [
    "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0c8901fc-8ee7-4055-93d5-bca892c16d04",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "0c8901fc-8ee7-4055-93d5-bca892c16d04",
    "outputId": "1dd1d88c-37c9-4fae-bf6c-b84b5b1bee21",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Here are the answers to your questions:\n",
      "\n",
      "**Question 1: Which concept is explained in the video?**\n",
      "\n",
      "The video explains the concept of **Linear Regression**, a type of supervised learning model. \n",
      "\n",
      "**Question 2: Based on your answer to Question 1, can you explain the basic math of this concept?**\n",
      "\n",
      "Linear regression aims to find the best-fitting line through a set of data points. The equation of this line is:\n",
      "\n",
      "**y = wx + b**\n",
      "\n",
      "* **y**: The target variable (dependent variable) we want to predict.\n",
      "* **x**: The input feature (independent variable) used to predict y.\n",
      "* **w**: The weight vector, which determines the slope of the line.\n",
      "* **b**: The bias term, which determines the y-intercept of the line.\n",
      "\n",
      "The goal of linear regression is to find the values of w and b that minimize the difference between the predicted y values and the true y values in the dataset. \n",
      "\n",
      "**Question 3: Can you provide a simple scikit code example explaining the concept?**\n",
      "\n",
      "```python\n",
      "import pandas as pd\n",
      "from sklearn.linear_model import LinearRegression\n",
      "from sklearn.model_selection import train_test_split\n",
      "\n",
      "# Sample data\n",
      "data = {'Square Footage': [1000, 1200, 1500, 1800, 2000], \n",
      "        'House Price': [150000, 180000, 220000, 270000, 300000]}\n",
      "df = pd.DataFrame(data)\n",
      "\n",
      "# Split data into training and testing sets\n",
      "X_train, X_test, y_train, y_test = train_test_split(\n",
      "    df[['Square Footage']], df['House Price'], test_size=0.2)\n",
      "\n",
      "# Create a linear regression model\n",
      "model = LinearRegression()\n",
      "\n",
      "# Train the model\n",
      "model.fit(X_train, y_train)\n",
      "\n",
      "# Make predictions on the test set\n",
      "predictions = model.predict(X_test)\n",
      "\n",
      "# Evaluate the model\n",
      "print(model.score(X_test, y_test))  # R-squared score\n",
      "\n",
      "# Print the coefficients\n",
      "print(f'Slope: {model.coef_[0]}')\n",
      "print(f'Intercept: {model.intercept_}')\n",
      "```\n",
      "\n",
      "This code demonstrates:\n",
      "\n",
      "1. **Data Preparation:** Loading sample house price data into a Pandas DataFrame.\n",
      "2. **Data Splitting:** Dividing the data into training and testing sets for model evaluation.\n",
      "3. **Model Creation:** Initializing a LinearRegression object from scikit-learn.\n",
      "4. **Model Training:** Fitting the model to the training data using the `.fit()` method.\n",
      "5. **Predictions:** Generating predictions on the test data using the `.predict()` method.\n",
      "6. **Evaluation:** Calculating the R-squared score to assess model performance.\n",
      "7. **Coefficients:** Printing the slope (w) and intercept (b) of the learned linear model.\n",
      "\n",
      "This simple example showcases how linear regression can be implemented in Python using scikit-learn to predict house prices based on square footage. \n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(responses.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09da9100-165b-4968-a14d-b264c86f574b",
   "metadata": {
    "id": "09da9100-165b-4968-a14d-b264c86f574b"
   },
   "source": [
    "- You can copy/paste and run your generated code in the cell below.\n",
    "\n",
    "**Note:** LLM's are known to generate code which is incomplete or has bugs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8568ea9-8c05-48b4-b3c5-84e0f83a5a8d",
   "metadata": {
    "id": "d8568ea9-8c05-48b4-b3c5-84e0f83a5a8d"
   },
   "outputs": [],
   "source": [
    "### you can copy/paste your generated code here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23746f67-e028-40e7-879e-790aef78dffa",
   "metadata": {
    "id": "23746f67-e028-40e7-879e-790aef78dffa"
   },
   "source": [
    "- Below cell includes the code which was generated in the lecture video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e156d4-9e2d-4c99-9250-cb853e5ff397",
   "metadata": {
    "id": "64e156d4-9e2d-4c99-9250-cb853e5ff397",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# # Import the necessary libraries\n",
    "# import numpy as np\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# # Create some data\n",
    "# X = np.array([[1, 1], [1, 2], [2, 2], [2, 3]])\n",
    "# y = np.dot(X, np.array([1, 2])) + 3\n",
    "\n",
    "# # Fit the linear regression model\n",
    "# model = LinearRegression()\n",
    "# model.fit(X, y)\n",
    "\n",
    "# # Make predictions\n",
    "# y_pred = model.predict(X)\n",
    "\n",
    "# # Plot the data and the fitted line\n",
    "# plt.scatter(X[:, 1], y)\n",
    "# plt.plot(X[:, 1], y_pred, color='red')\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc9d06e1-a537-46dd-bd7b-5ad3cedce500",
   "metadata": {
    "id": "bc9d06e1-a537-46dd-bd7b-5ad3cedce500"
   },
   "source": [
    "## Extracting Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "537892cf-d107-4542-98b8-f381ede35a07",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 275
    },
    "id": "537892cf-d107-4542-98b8-f381ede35a07",
    "outputId": "65fc615d-237c-4532-a5e1-b90e66a6d2af",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"https://storage.googleapis.com/dlai-sc-gemini-bucket/google-search.mp4\" controls  width=\"450\" >\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_path_4 = \"dlai-sc-gemini-bucket/google-search.mp4\"\n",
    "video_uri_4 = f\"gs://{file_path_4}\"\n",
    "video_url_4 = f\"https://storage.googleapis.com/{file_path_4}\"\n",
    "\n",
    "IPython.display.Video(video_url_4, width=450)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "6d2a8301-2ff1-4e42-a93f-0e79ac467730",
   "metadata": {
    "id": "6d2a8301-2ff1-4e42-a93f-0e79ac467730",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_4 = Part.from_uri(video_uri_4, mime_type=\"video/mp4\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1adb0e3-44b5-4701-8a37-2acb7a6d3d10",
   "metadata": {
    "id": "d1adb0e3-44b5-4701-8a37-2acb7a6d3d10"
   },
   "source": [
    "**Note:** In the lecture video, everything was put in a single prompt (`prompt_4`):\n",
    "\n",
    "```Python\n",
    "prompt_4 = \"\"\"\n",
    "Answer the following questions using the video only.\n",
    "Present the results in a table with a row for each question\n",
    "and its answer.\n",
    "Make sure the table is in markdown format.\n",
    "\n",
    "Questions:\n",
    "- What is the most searched sport?\n",
    "- Who is the most searched scientist?\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "contents_4 = [video_4, prompt_4]\n",
    "```\n",
    "But as also mentioned in the lecture, you can break it into seperate variables (`questions` and `format_html`), as done in the notebook below. Feel free to pause the video and compare your notebook with the video to see the differences."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2a11497-5a76-4d00-93b6-2d2f701d4474",
   "metadata": {
    "id": "e2a11497-5a76-4d00-93b6-2d2f701d4474"
   },
   "source": [
    "- Here, you have your questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "7061e11d-b17b-4f7a-96fb-ec1515a6d2a4",
   "metadata": {
    "id": "7061e11d-b17b-4f7a-96fb-ec1515a6d2a4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = \"\"\"\n",
    "Answer the following questions using the video only.\n",
    "\n",
    "Questions:\n",
    "- What is the most searched sport?\n",
    "- Who is the most searched scientist?\n",
    "\"\"\"\n",
    "\n",
    "# questions = \"\"\"\n",
    "# Answer the following questions using the video only.\n",
    "# If the answer is not found in the video,\n",
    "# say \"Not found in video\".\n",
    "\n",
    "# Questions:\n",
    "# - What is the most searched sport?\n",
    "# - Who is the most searched scientist?\n",
    "# \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b134862-4be8-4373-96aa-15f90b985396",
   "metadata": {
    "id": "3b134862-4be8-4373-96aa-15f90b985396"
   },
   "source": [
    "- Here, you specify the output format.\n",
    "- In this case, it is table format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a0c633fa-b953-474b-a8e8-7bbfe7d919b0",
   "metadata": {
    "id": "a0c633fa-b953-474b-a8e8-7bbfe7d919b0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "format_html = \"\"\"\n",
    "Format:\n",
    "Present the results in a table with a row for each question\n",
    "and its answer.\n",
    "Make sure the table is in markdown format.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "cf756730-718f-47c4-82e9-2b598fc35b44",
   "metadata": {
    "id": "cf756730-718f-47c4-82e9-2b598fc35b44",
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents_4 = [video_4, questions, format_html]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14840809-732a-45f2-9222-c7c5faef0cb5",
   "metadata": {
    "id": "14840809-732a-45f2-9222-c7c5faef0cb5"
   },
   "source": [
    "- Set the `temperature`. For now, it is `temperature=0.9`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9e9b0ab0-7955-49a7-8f0c-5d106ae469db",
   "metadata": {
    "id": "9e9b0ab0-7955-49a7-8f0c-5d106ae469db",
    "tags": []
   },
   "outputs": [],
   "source": [
    "generation_config_1 = GenerationConfig(\n",
    "    temperature=0.9,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "a6a09877-2d8a-46f6-b1eb-5389151f927a",
   "metadata": {
    "id": "a6a09877-2d8a-46f6-b1eb-5389151f927a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "responses = multimodal_model.generate_content(contents_4,\n",
    "                   generation_config=generation_config_1,\n",
    "                                              stream=True\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac63287-d25b-4b13-84c1-852c6f5b708e",
   "metadata": {
    "id": "1ac63287-d25b-4b13-84c1-852c6f5b708e"
   },
   "source": [
    "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "afd17035-a22d-48f8-9850-bd2a8d8e1568",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "afd17035-a22d-48f8-9850-bd2a8d8e1568",
    "outputId": "b205f918-741d-4518-a80c-649f4fd3b1fe",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "| Question | Answer |\n",
      "|---|---|\n",
      "| What is the most searched sport? | Soccer/Football |\n",
      "| Who is the most searched scientist? | Albert Einstein |"
     ]
    }
   ],
   "source": [
    "for response in responses:\n",
    "    print(response.text, end=\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d527184e-4b9e-404f-ac58-7510110fb006",
   "metadata": {
    "id": "d527184e-4b9e-404f-ac58-7510110fb006"
   },
   "source": [
    "```\n",
    "You can copy/paste your generation in this Markdown cell (double click here)\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39889919-f32c-4fe6-a5d2-3ebcccacc3c4",
   "metadata": {
    "id": "39889919-f32c-4fe6-a5d2-3ebcccacc3c4"
   },
   "source": [
    "## Finding a Needle in a Haystack"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9e7f61b-2f04-4226-b905-9c714573ba63",
   "metadata": {
    "id": "e9e7f61b-2f04-4226-b905-9c714573ba63"
   },
   "source": [
    "- Load the [gemini-1.5-pro-001](https://console.cloud.google.com/vertex-ai/publishers/google/model-garden/gemini-pro-preview-0409) model.\n",
    "\n",
    "<span style=\"color:red; font-weight:bold;\">IMPORTANT ⚠️ : For this example, `gemini-1.5-pro-001` was used in the lecture video</span>\n",
    "\n",
    "<span style=\"color:red; font-weight:bold;\"> - PROMPTING THIS NEEDLE IN A HAYSTACK EXAMPLE SHOULD COST LESS THAN 5.0 USD PER EXECUTION WITH `gemini-1.5-pro-001` (as of August 2024). </span>\n",
    "\n",
    "<span style=\"color:green; font-weight:bold;\"> - Using `gemini-1.5-flash-001` instead should cost less than 0.25 USD (as of August 2024) per execution. </span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1eca11af-1cd6-4b70-96e7-1b20898de566",
   "metadata": {
    "id": "1eca11af-1cd6-4b70-96e7-1b20898de566",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# multimodal_model = GenerativeModel(\"gemini-1.5-pro-001\")\n",
    "\n",
    "multimodal_model = GenerativeModel(\"gemini-1.5-flash-001\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e54edcd-4c29-411e-aabf-c5b26e48b8f7",
   "metadata": {
    "id": "5e54edcd-4c29-411e-aabf-c5b26e48b8f7"
   },
   "source": [
    "- Just like with images, you can send more than 1 video to the model.\n",
    "- The following videos are from the **[LLMOps](https://learn.deeplearning.ai/courses/llmops/lesson/1/introduction)** short course, which you can enroll in on **[DeepLearning.AI's Short Courses Platform](https://learn.deeplearning.ai)**."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "c28074ef-2c8c-4008-a83e-c8b3140eeb9a",
   "metadata": {
    "id": "c28074ef-2c8c-4008-a83e-c8b3140eeb9a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "video_1 = Part.from_uri(\"gs://dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L1_v3.mp4.mp4\",  mime_type=\"video/mp4\")\n",
    "video_2 = Part.from_uri(\"gs://dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L2_v4.mp4\",  mime_type=\"video/mp4\")\n",
    "video_3 = Part.from_uri(\"gs://dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L3_v4.mp4\",  mime_type=\"video/mp4\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "555ad4b4-9918-4fbc-8ecb-d957a16d8b4a",
   "metadata": {
    "id": "555ad4b4-9918-4fbc-8ecb-d957a16d8b4a",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from IPython.display import IFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c384cb3-c0d5-4ac8-a4f3-8340f92a4d96",
   "metadata": {
    "id": "3c384cb3-c0d5-4ac8-a4f3-8340f92a4d96"
   },
   "source": [
    "- This displays only one of the three videos.\n",
    "- To view others, feel free to change the `file_path`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "17f6bdb1-8c6d-4e5c-83fb-294507a6f37d",
   "metadata": {
    "id": "17f6bdb1-8c6d-4e5c-83fb-294507a6f37d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "file_path = \"dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L2_v4.mp4\"\n",
    "video_url = f\"https://storage.googleapis.com/{file_path}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7e26e417-56e2-4d0c-a955-374c675f868f",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 337
    },
    "id": "7e26e417-56e2-4d0c-a955-374c675f868f",
    "outputId": "a1f06fe1-6885-48b9-f720-3163856468ee",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"560\"\n",
       "            height=\"315\"\n",
       "            src=\"https://storage.googleapis.com/dlai-sc-gemini-bucket/sc-gc-c3-LLMOps_L2_v4.mp4\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x7c49284aaf50>"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "IFrame(video_url, width=560, height=315)  # Adjust width and height as needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a70ed794-959c-4777-8fad-00e7b20a541d",
   "metadata": {
    "id": "a70ed794-959c-4777-8fad-00e7b20a541d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "role = \"\"\"\n",
    "You are specialized in analyzing videos and finding \\\n",
    "a needle in a haystack.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "f4df3088-f7ed-43b6-b148-1fb7549797d6",
   "metadata": {
    "id": "f4df3088-f7ed-43b6-b148-1fb7549797d6",
    "tags": []
   },
   "outputs": [],
   "source": [
    "instruction = \"\"\"\n",
    "Here are three videos. Each is a lesson from the \\\n",
    "LLMOps course from Deep Learning AI.\n",
    "Your answers are only based on the videos.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c04e5717-1495-4d69-93a2-93e0e3fc1959",
   "metadata": {
    "id": "c04e5717-1495-4d69-93a2-93e0e3fc1959"
   },
   "source": [
    "- You are asking the model (question 2) to find something very specific from across these 3 videos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4dbcc5af-aca5-4f1b-82cd-36966fb690e2",
   "metadata": {
    "id": "4dbcc5af-aca5-4f1b-82cd-36966fb690e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "questions = \"\"\"\n",
    "Answer the following questions:\n",
    "1. Create a summary of each video and what is discussed in \\\n",
    "the video.\\\n",
    "Limit the summary to a max of 100 words.\n",
    "2. In which of the three videos does the instructor run \\\n",
    "and explains this Python code: bq_client.query(). \\\n",
    "Where do you see this code in the video?\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "cda6a861-271a-4acb-ab84-8cac8ce0a9b3",
   "metadata": {
    "id": "cda6a861-271a-4acb-ab84-8cac8ce0a9b3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "contents_5 = [\n",
    "    role,\n",
    "    instruction,\n",
    "    video_1,\n",
    "    video_2,\n",
    "    video_3,\n",
    "    questions\n",
    "]\n",
    "\n",
    "# contents_5 = [\n",
    "#     instruction,\n",
    "#     video_1,\n",
    "#     video_2,\n",
    "#     video_3,\n",
    "#     questions,\n",
    "#     role,\n",
    "# ]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fab0a1be-1035-4648-9aa2-2b35e0766423",
   "metadata": {
    "id": "fab0a1be-1035-4648-9aa2-2b35e0766423"
   },
   "source": [
    "**Note:** We have commented out the code to prevent accidental execution\n",
    "\n",
    "```Python\n",
    "responses = multimodal_model.generate_content(\n",
    "    contents_5,\n",
    "    stream=True\n",
    ")\n",
    "```\n",
    "\n",
    "**Note**: LLM's do not always produce the same results, especially because they are frequently updated. So the output you see in the video might be different than what you may get.\n",
    "\n",
    "```Python\n",
    "### this will take some time to run\n",
    "\n",
    "for response in responses:\n",
    "    print(response.text, end=\"\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "YSGuJqjgD-2I",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YSGuJqjgD-2I",
    "outputId": "68485dfe-08cb-4524-b911-ebbcb9c4b7b6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Okay, here is a summary of each video: \n",
      "\n",
      "**Video 1 Summary:** The first video of the LLMOps course is an introduction to the fundamental concepts and ideas within LLMOps. The instructor explains the relationship between LLMOps and MLOps as well as how LLMOps differs from traditional MLOps. Key terms covered include data management, automation, and deployment as well as their importance in LLMOps and how they relate to one another. An example is given highlighting a typical LLMOps workflow. \n",
      "\n",
      "**Video 2 Summary:** The instructor continues to delve into the key concepts and components of LLMOps in the second video of the course by showing how to retrieve text data from a BigQuery data warehouse. The importance of dealing with large datasets that cannot fit into memory is highlighted. The instructor uses SQL to query a database that is too large to fit into memory, ultimately resulting in an error. \n",
      "\n",
      "**Video 3 Summary:** The third video of the LLMOps course moves into more advanced concepts like containers, pipelines, and the Kubeflow Pipeline DSL. The instructor explains what containers and pipelines are in the context of LLMOps. A simple 'hello world' pipeline is built and deployed to Google Cloud using Vertex AI Pipelines. \n",
      "\n",
      "\n",
      "**Question 2 Answer:** The instructor runs and explains the code `bq_client.query()` in the **second** video. The code is seen at **03:59 of the second video**. \n"
     ]
    }
   ],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "environment": {
   "kernel": "python3",
   "name": "tf2-cpu.2-11.m114",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-cpu.2-11:m114"
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
